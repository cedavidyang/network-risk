{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare performance of TMCMC vs others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import multiprocess as mp\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "from UQpy.sampling import MetropolisHastings\n",
    "from UQpy.distributions import Normal, Uniform, MultivariateNormal\n",
    "\n",
    "from parallel_tempMCMC import SequentialTemperingMCMCpar\n",
    "from temper_benchmark import scenario_logp, scenario_logC, precise_risk, log_pdf_intermediate\n",
    "from highway_risk_temper import get_damage_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants shared by different evaluation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random_state for repeatability\n",
    "random_state = 1\n",
    "\n",
    "# parallel computing\n",
    "n_jobs = 1\n",
    "\n",
    "# small number of numerical stability\n",
    "eps = 1e-6\n",
    "\n",
    "# bridge number and their reliability limits\n",
    "n_br, min_beta, max_beta = 30, 0, 3+eps\n",
    "\n",
    "# generate beta array for all bridge links\n",
    "beta_array = Uniform(loc=min_beta, scale=max_beta-min_beta,).rvs(\n",
    "    nsamples=n_br, random_state=1)\n",
    "beta_array = beta_array.flatten()\n",
    "beta_array.sort()\n",
    "pf_array = Normal().cdf(-beta_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change `cost_type` between `'add'` and `'swan'` to compare additive cost and grey-swan cost, respectively. Define `cost_array` and `cost_base` based on `cost_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_type = 'add'\n",
    "\n",
    "if cost_type == 'add':\n",
    "    cost_array = np.arange(1.0, 1.0+n_br, 1)\n",
    "    cost_base = 0.0\n",
    "elif cost_type == 'swan':\n",
    "    cost_array = np.power(10**beta_array, np.linspace(0.0, 1.0, n_br))\n",
    "    cost_array[:-3] = 1e-3\n",
    "    cost_base = 1.1    # when cost_type='swan', having a cost_base larger than 1 improves resampling process\n",
    "else:\n",
    "    raise RuntimeError(\"Unknown cost_type: must be 'add' or 'swan'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The precise risk for this problem can be determined as follows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precise risk = 39.448804452293125\n"
     ]
    }
   ],
   "source": [
    "risk0 = precise_risk(pf_array, cost_array, cost_type=cost_type, cost_base=cost_base)\n",
    "print(f'precise risk = {risk0}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TMCMC Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up TMCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TMCMC constants\n",
    "n_chains, resample_pct, n_smp = 100, 10, 5000\n",
    "n_burn, n_jump = 1000, 10\n",
    "covar = 0.5**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some combinations of `resample_pct`, `n_smp`, and `n_chains`, the true resampling percentage may be different from the specified `resample_pct`.\n",
    "\n",
    "The following cell is optional and provides the true resampling percentage used in TMCMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True resampling pct is 0.1 (nominal: 0.1)\n"
     ]
    }
   ],
   "source": [
    "n_samples_per_chain = int(np.floor(((1 - resample_pct/100) * n_smp) / n_chains))\n",
    "n_resamples = int(n_smp - (n_samples_per_chain * n_chains))\n",
    "\n",
    "# no. of chains cannot be higher than the no. of resamples points\n",
    "if n_resamples < n_chains:\n",
    "    # reduce no of chains\n",
    "    n_chains = n_resamples\n",
    "\n",
    "print(f'True resampling pct is {n_resamples/n_smp} (nominal: {resample_pct/100})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct TMCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following parameters seem to have a significant impact on the sampling quality:\n",
    "\n",
    "* `resample_pct` that controls how many samples are reused between stages. 10% from the literature seems perform well here.\n",
    "\n",
    "* Parameters of `mcmc_sampler`, including `n_chains` (number of Markov chains with different heads), `n_burn` (number of burn-in samples), and `n_jump` (number of samples to skip along a Markov chain)\n",
    "\n",
    "Note that the way `random_state` is used is different between serial run and parrallel run. Therefore, the results are different even though the same `random_state` is used.\n",
    "\n",
    "Also, when using parallel computing, `damage_db` will not be populated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# damage database to avoid redundant computation\n",
    "damage_db = dict()\n",
    "\n",
    "# prior distribution of hidden variables mapped to asset state\n",
    "prior = MultivariateNormal(mean=[0.0]*n_br, cov=1.0)\n",
    "\n",
    "# mcmc_sampler is the MCMC used to generate new samples (after resampling)\n",
    "mcmc_sampler = MetropolisHastings(\n",
    "    dimension=n_br, n_chains=n_chains,\n",
    "    proposal=MultivariateNormal(mean=[0.0]*n_br, cov=covar),\n",
    "    burn_length=n_burn, jump=n_jump,\n",
    ")\n",
    "\n",
    "# provide explicit prior log_pdf (due to multiprocess cannot pickle objects)\n",
    "prior_log_pdf = lambda x: prior.log_pdf(x)\n",
    "\n",
    "# intermediate likelihood function\n",
    "use_log_pdf = lambda x, b: log_pdf_intermediate(\n",
    "    x, b, beta_array=beta_array, cost_array=cost_array,\n",
    "    cost_base=cost_base, damage_db=damage_db, epsilon=eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create TMCMC sampler and obtain the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = SequentialTemperingMCMCpar(\n",
    "    log_pdf_intermediate=use_log_pdf,\n",
    "    distribution_reference=prior,\n",
    "    save_intermediate_samples=True,\n",
    "    percentage_resampling=resample_pct,\n",
    "    sampler=mcmc_sampler,\n",
    "    weight_cov_threshold=0.2,\n",
    "    random_state=random_state,\n",
    "    nsamples=n_smp,\n",
    ")\n",
    "time0 = time.time()\n",
    "if n_jobs == 1:\n",
    "    sampler.run(nsamples=n_smp)\n",
    "else:\n",
    "    sampler.parallel_run(nsamples=n_smp, n_jobs=n_jobs,\n",
    "                         log_pdf_intermediate=use_log_pdf,\n",
    "                         prior_log_pdf=prior_log_pdf)\n",
    "time1 = time.time()\n",
    "\n",
    "# get samples\n",
    "samples = sampler.samples\n",
    "\n",
    "# retrieve damage condition and unique damage condition from last-stage samples\n",
    "damage_condition = get_damage_state(samples, beta_array).astype(int)\n",
    "unique_condition, counts = np.unique(damage_condition, axis=0, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Report sampling results:**\n",
    "\n",
    "* `evidence`: estimated risk plus `cost_base`\n",
    "\n",
    "* `max_analysis`: number of unique cost evaluations during sampling\n",
    "\n",
    "* `max_smp`: number of samples generated in all stages\n",
    "\n",
    "The latter two (`max_analysis` and `max_smp`), together with running time (`time1-time0`), control the termination of crude Monte Carlo simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 10.836361646652222 sec\n",
      "number of chains: 100\n",
      "number of stages: 4\n",
      "samples per stage: 5000\n",
      "number of all samples: 200000\n",
      "number of net analysis: 0\n",
      "evidence estimated: 38.78292577743867\n",
      "risk estimated (TMCMC): 38.78292577743867\n"
     ]
    }
   ],
   "source": [
    "# get the estimated evidence\n",
    "evidence = sampler.evidence\n",
    "\n",
    "total_analysis = len(list(damage_db))\n",
    "all_smp = np.vstack(sampler.intermediate_samples)\n",
    "total_smp = all_smp.shape[0]*n_jump\n",
    "total_time = (time1-time0)*n_jobs\n",
    "\n",
    "print(f'Completed in {total_time} sec')\n",
    "print(f'number of chains: {n_chains}')\n",
    "print(f'number of stages: {len(sampler.intermediate_samples)}')\n",
    "print(f'samples per stage: {n_smp}')\n",
    "print(f'number of all samples: {total_smp}')\n",
    "print(f'number of net analysis: {total_analysis}')\n",
    "print(f'evidence estimated: {evidence[0]}')\n",
    "print(f'risk estimated (TMCMC): {evidence[0]-cost_base}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MC Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve fair comparison, MC is terminated based on computational costs (`max_analysis`. `max_smp`, and runtime) from TMCMC. Therefore, TMCMC must be run first before runnning subsequent cells.\n",
    "\n",
    "Alternatively, one can uncomment lines in the following cell to run MC directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_analysis = 10000\n",
    "# max_smp = 100000\n",
    "# max_time = np.inf\n",
    "\n",
    "max_analysis = total_analysis if total_analysis>0 else 2**n_br\n",
    "max_smp = total_smp\n",
    "max_time = total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get MC samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_rv = MultivariateNormal(mean=[0.0]*n_br, cov=1.0)\n",
    "condition_rvs_max = condition_rv.rvs(nsamples=max_smp, random_state=random_state)\n",
    "\n",
    "damage_db_MC = dict()\n",
    "C_smp_list = []\n",
    "time0 = time.time()\n",
    "for i, condition_rvs in enumerate(condition_rvs_max):\n",
    "\n",
    "    condition_rvs = condition_rvs.reshape((-1,1))\n",
    "\n",
    "    logC = scenario_logC(\n",
    "        condition_rvs, beta_array=beta_array,\n",
    "        cost_array=cost_array,\n",
    "        from_condition=False,\n",
    "        cost_type=cost_type,\n",
    "        cost_base=cost_base,\n",
    "        damage_db=damage_db_MC,\n",
    "        epsilon=eps,\n",
    "    )\n",
    "\n",
    "    C_smp = np.exp(logC).flatten()[0]\n",
    "    C_smp_list.append(C_smp)\n",
    "    \n",
    "    time1 = time.time()\n",
    "\n",
    "    # check if terminate before max_samp\n",
    "    n_analysis = len(list(damage_db_MC))\n",
    "    if (n_analysis >= max_analysis) or (time1-time0>max_time):\n",
    "        break\n",
    "\n",
    "C_smp_array = np.array(C_smp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Report results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 10.836597919464111 sec\n",
      "number of samples: 26028 vs 200000\n",
      "number of net analysis: 0 vs. 1073741824\n",
      "risk estimated: 39.72521999492854\n"
     ]
    }
   ],
   "source": [
    "R_net = np.mean(C_smp_array)\n",
    "\n",
    "print(f'Completed in {time1-time0} sec')\n",
    "print(f'number of samples: {C_smp_array.shape[0]} vs {max_smp}')\n",
    "print(f'number of net analysis: {len(list(damage_db_MC))} vs. {max_analysis}')\n",
    "print(f'risk estimated: {R_net}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk-bound Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up risk-bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similary, the following cells require running TMCMC first to achieve fair comparison.\n",
    "\n",
    "Also, since it requires a non-empty `damage_db`, TMCMC should be conducted using the series version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if damage_db is empty, assume all samples require a new cost evaluation\n",
    "total_scenario = total_analysis if total_analysis>0 else max_smp\n",
    "\n",
    "# n_fail = 2\n",
    "# total_scenario = np.sum([comb(n_br, j) for j in range(1, n_fail+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct risk-bound estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_indx = cost_array.argsort()[::-1]\n",
    "comb_condition = []\n",
    "nsc = 0\n",
    "for failed in range(0, n_br+1):\n",
    "    for indx in itertools.combinations(sorting_indx, failed):\n",
    "        key = np.zeros(n_br, dtype=bool)\n",
    "        key[(indx,)] = True\n",
    "        comb_condition.append(key)\n",
    "        nsc += 1\n",
    "        if nsc >= total_scenario:\n",
    "            break\n",
    "    if nsc >= total_scenario:\n",
    "        break\n",
    "\n",
    "comb_condition = np.array(comb_condition)\n",
    "logp_comb = scenario_logp(comb_condition, beta_array, from_condition=True)\n",
    "logC_comb = scenario_logC(comb_condition, beta_array, cost_array,\n",
    "                          from_condition=True, cost_type=cost_type,\n",
    "                          cost_base=cost_base, damage_db=None, epsilon=eps)\n",
    "\n",
    "all_fail = np.ones((1, n_br), dtype=bool)\n",
    "logC_max = scenario_logC(all_fail, beta_array, cost_array,\n",
    "                         from_condition=True, cost_type=cost_type,\n",
    "                         cost_base=cost_base, damage_db=None, epsilon=eps)[0]\n",
    "\n",
    "logC_min = np.min(cost_array.min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Report results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimation (no remaining) = 16.671498174697582\n",
      "estimation (w/ remaining) lower = 17.795304964223387\n",
      "estimation (w/ remaining) upper = 208.91431596579582\n"
     ]
    }
   ],
   "source": [
    "# estimate risk\n",
    "logpC_comb = logp_comb + logC_comb\n",
    "risk_bound0 = np.sum(np.exp(logpC_comb))\n",
    "\n",
    "# remaining probs\n",
    "p_remain = np.maximum(0, 1-np.exp(logp_comb).sum())\n",
    "risk_bound1 = risk_bound0 + p_remain*np.exp(logC_min)\n",
    "risk_bound2 = risk_bound0 + p_remain*np.exp(logC_max)\n",
    "\n",
    "print(f'estimation (no remaining) = {risk_bound0}')\n",
    "print(f'estimation (w/ remaining) lower = {risk_bound1}')\n",
    "print(f'estimation (w/ remaining) upper = {risk_bound2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
